{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d335e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89807925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hotels2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6fcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[576], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609b4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of obervations where address is 'South San Francisco'\n",
    "south_sf = []\n",
    "for i in df.address:\n",
    "    if 'South San Francisco' in i:\n",
    "        south_sf.append(df[df.address == i].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a16e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the obervations where address is 'South San Francisco'\n",
    "# in order to only keep address with 'San Francisco'\n",
    "for i in south_sf:\n",
    "    df.iloc[i, 1] = np.nan\n",
    "    \n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4137d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all text lowercase\n",
    "df['area_star_processed'] = df.area_star.apply(lambda x: x.lower())\n",
    "\n",
    "# remove punctuation\n",
    "df.area_star_processed = (df.area_star_processed\n",
    "                     .apply(\n",
    "                         lambda x: \n",
    "                         re.sub('[%s]' %re.escape(string.punctuation),'', x)))\n",
    "\n",
    "# remove numbers\n",
    "df.area_star_processed = (df.area_star_processed\n",
    "                     .apply(lambda x: re.sub('\\w*\\d\\w*', '', x)))\n",
    "\n",
    "# remove '\\n' and '–'\n",
    "df.area_star_processed = (df.area_star_processed\n",
    "                     .apply(lambda x: re.sub('[\\n–]', '', x)))\n",
    "\n",
    "\n",
    "# Remove terms that appear in many of the combined description\n",
    "# because it is interfering with the topic modeling. They are\n",
    "# showing up as topics rather than terms that are more \n",
    "# meaningful\n",
    "def remove_terms(terms):\n",
    "    for term in terms:\n",
    "        df.area_star_processed = (df.area_star_processed\n",
    "                                  .apply(lambda x: \n",
    "                                         x.replace(\n",
    "                                             term, '')))\n",
    "\n",
    "\n",
    "         \n",
    "terms = ['hikingbiking trails', 'cultural highlights', 'area', 'worth', \n",
    "         'attractions', 'neighborhood', 'event', 'game', 'located', 'include',\n",
    "         'looking', 'natural', 'beauty', 'enjoy', 'town', 'visit', 'agenda', \n",
    "         'hotels', 'wishing', 'near', 'nearby', 'whats', 'checking', 'kayaking',\n",
    "         'shopping', 'consider', 'adventure', 'adventures', 'seek', 'activity',\n",
    "         'activities', 'hotel', 'public', 'transportation', 'guests', 'night',\n",
    "         'love', 'foot', 'location', 'discover', 'city', 'great', 'club', 'clubs',\n",
    "         'going', 'golf', 'landmarks', 'explore', 'water', 'local', 'traveler', \n",
    "         'want', 'shop', 'minutes', 'inn', 'spend', 'appreciate', 'notable', 'happen', \n",
    "         'convenience', 'experience', 'stop', 'good', 'seen', 'metro', 'station',\n",
    "         'music', 'beach', 'maritime', 'pacific', 'shrine', 'auditorium', 'theater',\n",
    "         'bell', 'national', 'science', 'hollywood', 'county', 'california', 'center',\n",
    "         'one star', 'two stars', 'three stars', 'four stars', 'five stars']\n",
    "\n",
    "remove_terms(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c876ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corpus of combined star rating and area description\n",
    "area_star_corpus = []\n",
    "for text in df.area_star_processed:\n",
    "    area_star_corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b19c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize compound attraction terms\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer\n",
    "\n",
    "mwe_tokenizer = MWETokenizer([('new', 'york'), ('los', 'angeles'), \n",
    "('san', 'francisco'), ('oracle', 'park'), ('chase', 'center'),('millennium', 'park'),\n",
    "('bay', 'ferry', 'building'), ('berkeley', 'marina'), ('westfield', 'san', 'francisco', 'centre'),\n",
    "('ferry', 'building', 'marketplace'), ('one', 'star'), ('two', 'stars'), ('three', 'stars'), ('four', 'stars'),\n",
    "('five', 'stars'), ('ghirardelli', 'square'), ('san', 'franciso', 'maritime', 'national', 'historical', 'park'),\n",
    "('cable', 'car', 'museum'), ('fort', 'mason'), ('alcatraz', 'island'),\n",
    "('aquarium', 'of', 'the', 'bay'), ('embarcadero', 'center'),\n",
    "('muir', 'woods', 'national', 'monument'), ('financial', 'district'),\n",
    "('lombard', 'street'), ('golden', 'gate', 'park'), ('hillsdale', 'shopping', 'center'),\n",
    "('coyote', 'point', 'park'), ('half', 'moon', 'bay', 'parkside', 'aquatic', 'park'),\n",
    "('casanova', 'park'), ('grace', 'cathedral'), ('painted', 'ladies'),\n",
    "('burlingame', 'museum'), ('san', 'franciso', 'museum', 'of', 'modern', 'art'),\n",
    "('california', 'academy', 'of', 'sciences'), ('santa', 'monica', 'pier'),\n",
    "('hollywood', 'walk', 'of', 'fame'), ('the', 'grove'), ('universal', 'citywalk'),\n",
    "('universal', 'studios'), ('venice', 'beach'), ('airport', 'proximity'),\n",
    "('hermosa', 'beach', 'pier'), ('muscle', 'beach'),\n",
    "('topanga', 'state', 'park'), ('dockweiler', 'state', 'beach'),\n",
    "('petersen', 'automotive', 'museum'), ('el', 'corazon'),\n",
    "('los', 'angeles', 'county', 'museum', 'of', 'art'), ('farmers', 'market'),\n",
    "('melrose', 'avenue'), ('city', 'center'),\n",
    "('nethercutt', 'museum'), ('rancho', 'camulos'), ('six', 'flags'),\n",
    "('gibbon', 'conservation', 'center'), ('los', 'angeles', 'international', 'airport'),\n",
    "('el', 'capitan', 'theatre'), ('wilson', 'park'), ('south', 'botanic', 'garden'),\n",
    "('redondo', 'beach', 'pier'), ('del', 'amo', 'fashion', 'center'), \n",
    "('toyota', 'sports', 'center'), ('knots', 'berry', 'farm'), ('disneyland'),\n",
    "('old', 'town', 'pasadena'), ('griffith', 'observatory'), ('rose', 'bowl', 'stadium'),\n",
    "('warner', 'brothers', 'studio'), ('pantages', 'theatre'), ('hollywood', 'and', 'vine'),\n",
    "('pershing', 'square'), ('los', 'angeles', 'state', 'historic', 'park'), \n",
    "('grammy', 'museum'), ('natural', 'history', 'museum'), ('pasadena', 'museum'),\n",
    "('azusa', 'greens', 'coutnry', 'club'), ('los', 'angeles', 'equestrian', 'center'), \n",
    "('entertainment', 'district'), ('paramount', 'studios'), \n",
    "('hollywood', 'wax', 'museum'), ('city', 'center'), ('lumen', 'field'), \n",
    "('climate', 'pledge', 'arena'), ('showbox', 'sodo'), ('family', 'fun', 'center'),\n",
    "('starfire', 'sports', 'complex'), ('renton', 'memorial', 'stadium'), \n",
    "('showare', 'center'), ('seattle', 'paramount', 'theatre'), ('avenue', 'theater'),\n",
    "('seattle', 'great', 'wheel'), ('climate', 'pledge', 'arena'), ('hydroplane', 'and', 'raceboat', 'museum'),\n",
    "('great', 'american', 'casino'), ('silver', 'dollar', 'casino'), ('central', 'park'),\n",
    "('museum', 'of', 'modern', 'are'), ('radio', 'city', 'music', 'hall'), ('bryant', 'park'),\n",
    "('central', 'park', 'zoo'), ('american', 'museum', 'of', 'natural', 'history'),\n",
    "('washington', 'square', 'park'), ('battery', 'park'), ('barclays', 'center'),\n",
    "('empire', 'state', 'building'), ('time', 'square'), ('herald', 'square'),\n",
    "('madison', 'square', 'garden'), ('penn', 'station'), ('chelsea', 'market'),\n",
    "('flatiorn', 'building'), ('meadowlands', 'sports', 'complex'), ('st', 'james', 'theatre'),\n",
    "('river', 'north'), ('lake', 'michigan'), ('lakefront', 'trail'), ('skydeck', 'ledge'),\n",
    "('navy', 'pier'), ('the', 'loop'), ('business', 'district'), ('chicago', 'childrens', 'museum'),\n",
    "('state', 'street'), ('michigan', 'avenue'), ('field', 'museum', 'of', 'natural', 'history'),\n",
    "('chicago', 'riverwalk'), ('harris', 'theater'), ('chicago', 'cultural', 'center'),\n",
    "('frank', 'lloyd', 'wright', 'historic', 'district'), ('frank', 'lloyd', 'wright', 'home'),\n",
    "('rainbow', 'falls', 'waterpark'), ('parkway', 'bank', 'park', 'entertainment', 'district'),\n",
    "('kohl', 'childrens', 'museum'), ('fashion', 'outlets', 'of', 'chicago'),\n",
    "('harlem', 'irving', 'plaza'), ('lincoln', 'park', 'conservatory'),\n",
    "('peggy', 'notebaert', 'nature', 'museum'), ('promenade', 'bolingbrook'),\n",
    "('sea', 'lion', 'aquatic', 'park'), ('lake', 'katherine', 'nature', 'center'),\n",
    "('arboretum', 'of', 'south', 'barrington'), ('woodfield', 'mall'), ('santas', 'village'),\n",
    "('schaumburg', 'medieval', 'times'), ('legoland', 'discovery', 'center'),\n",
    "('raupp', 'memorial', 'museum'), ('grove', 'national', 'historic', 'landmark'),\n",
    "('northbrook', 'sports', 'complex'), ('wagner', 'farm'), ('lilacia', 'park'),\n",
    "('naper', 'settlement', 'museum'), ('cosley', 'zoo'), ('edge', 'ice', 'arena'),\n",
    "('seatgeek', 'stadium'), ('beach', 'navy', 'pier'), ('cloud', 'gate'),\n",
    "('grant', 'park'), ('millennium', 'park'), ('soldier', 'field'), ('seattle', 'aquarium'),\n",
    "('tmobile', 'park'), ('moore', 'theater'), ('gum', 'wall'), ('lincoln', 'square'),\n",
    "('marymoor', 'park'), ('husky', 'stadium'), ('bellevue', 'square'), ('coulon', 'memorial', 'park'),\n",
    "('lakeridge', 'park'), ('seattle', 'art', 'museum'), ('original', 'starbucks'),\n",
    "('climate', 'pledge', 'arena'), ('seatle', 'wheel'), ('washington', 'park', 'arboretum'),\n",
    "('woodland', 'park', 'zoo'), ('renton', 'memorial', 'statium'), ('sofi', 'stadium'),\n",
    "('pike', 'place', 'market'), ('space', 'needle'), ('staples', 'center')])\n",
    "\n",
    "mwe_corpus = []\n",
    "for i in area_star_corpus:\n",
    "    mwe_tokens = mwe_tokenizer.tokenize(word_tokenize(i))\n",
    "    mwe_corpus.append(mwe_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac65b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area_star_tokenized'] = [i for i in mwe_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed56bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "df.area_star_tokenized = (df.area_star_tokenized\n",
    "                          .apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb25f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokenized corpus\n",
    "area_star_corpus_tokenized = []\n",
    "for text in df.area_star_tokenized:\n",
    "    area_star_corpus_tokenized.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f822481c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbot</th>\n",
       "      <th>abri</th>\n",
       "      <th>ac</th>\n",
       "      <th>academy</th>\n",
       "      <th>ace</th>\n",
       "      <th>acme</th>\n",
       "      <th>adagio</th>\n",
       "      <th>addamsmedill</th>\n",
       "      <th>addition</th>\n",
       "      <th>adler</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>zachary</th>\n",
       "      <th>zelos</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zetta</th>\n",
       "      <th>ziplining</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoo</th>\n",
       "      <th>ändra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows × 1381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abbot  abri   ac  academy  ace  acme  adagio  addamsmedill  addition  \\\n",
       "0      0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "1      0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "2      0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "3      0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "4      0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "..     ...   ...  ...      ...  ...   ...     ...           ...       ...   \n",
       "990    0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "991    0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "992    0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "993    0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "994    0.0   0.0  0.0      0.0  0.0   0.0     0.0           0.0       0.0   \n",
       "\n",
       "        adler  ...     youre  zachary  zelos  zephyr  zeppelin  zetta  \\\n",
       "0    0.000000  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "1    0.000000  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "2    0.295512  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "3    0.000000  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "4    0.000000  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "..        ...  ...       ...      ...    ...     ...       ...    ...   \n",
       "990  0.000000  ...  0.275828      0.0    0.0     0.0       0.0    0.0   \n",
       "991  0.000000  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "992  0.000000  ...  0.296071      0.0    0.0     0.0       0.0    0.0   \n",
       "993  0.000000  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "994  0.000000  ...  0.000000      0.0    0.0     0.0       0.0    0.0   \n",
       "\n",
       "     ziplining  zoe       zoo  ändra  \n",
       "0          0.0  0.0  0.236161    0.0  \n",
       "1          0.0  0.0  0.000000    0.0  \n",
       "2          0.0  0.0  0.000000    0.0  \n",
       "3          0.0  0.0  0.000000    0.0  \n",
       "4          0.0  0.0  0.000000    0.0  \n",
       "..         ...  ...       ...    ...  \n",
       "990        0.0  0.0  0.000000    0.0  \n",
       "991        0.0  0.0  0.000000    0.0  \n",
       "992        0.0  0.0  0.000000    0.0  \n",
       "993        0.0  0.0  0.000000    0.0  \n",
       "994        0.0  0.0  0.000000    0.0  \n",
       "\n",
       "[995 rows x 1381 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tfidf Vectorizer to create a sparse matrix\n",
    "area_star_cv = TfidfVectorizer(stop_words='english')\n",
    "area_star_X = area_star_cv.fit_transform(area_star_corpus_tokenized).toarray()\n",
    "area_star_cv_df = pd.DataFrame(area_star_X, columns=area_star_cv.get_feature_names())\n",
    "area_star_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "662b8185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01887646, 0.04498003, 0.03229632, 0.02729887, 0.02242692])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_star_doc_word = area_star_cv.fit_transform(area_star_corpus_tokenized)\n",
    "\n",
    "area_star_lsa = TruncatedSVD(n_components=5)\n",
    "area_star_doc_topic = area_star_lsa.fit_transform(area_star_doc_word) \n",
    "area_star_lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b65b4616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbot</th>\n",
       "      <th>abri</th>\n",
       "      <th>ac</th>\n",
       "      <th>academy</th>\n",
       "      <th>ace</th>\n",
       "      <th>acme</th>\n",
       "      <th>adagio</th>\n",
       "      <th>addamsmedill</th>\n",
       "      <th>addition</th>\n",
       "      <th>adler</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>zachary</th>\n",
       "      <th>zelos</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zetta</th>\n",
       "      <th>ziplining</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoo</th>\n",
       "      <th>ändra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_0</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_4</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         abbot   abri     ac  academy    ace   acme  adagio  addamsmedill  \\\n",
       "topic_0  0.002  0.001  0.006    0.010  0.004  0.000   0.001         0.002   \n",
       "topic_1  0.002  0.003 -0.003    0.028 -0.000  0.000   0.003         0.002   \n",
       "topic_2  0.005 -0.001  0.004   -0.007  0.006  0.002  -0.001         0.009   \n",
       "topic_3  0.005  0.001 -0.001   -0.002  0.005 -0.001  -0.000        -0.002   \n",
       "topic_4  0.027  0.001  0.004    0.002 -0.000 -0.000  -0.000        -0.002   \n",
       "\n",
       "         addition  adler  ...  youre  zachary  zelos  zephyr  zeppelin  zetta  \\\n",
       "topic_0     0.004  0.003  ...  0.015    0.000  0.001   0.001     0.001  0.001   \n",
       "topic_1     0.011  0.002  ...  0.006    0.000  0.002   0.003     0.003  0.004   \n",
       "topic_2    -0.003  0.017  ...  0.010    0.004 -0.001  -0.000    -0.000 -0.002   \n",
       "topic_3    -0.001 -0.006  ... -0.007   -0.002 -0.000  -0.000    -0.000 -0.001   \n",
       "topic_4     0.001 -0.002  ...  0.003   -0.002 -0.000  -0.000     0.000 -0.001   \n",
       "\n",
       "         ziplining    zoe    zoo  ändra  \n",
       "topic_0      0.000  0.001  0.010  0.001  \n",
       "topic_1      0.000  0.003  0.013  0.001  \n",
       "topic_2      0.002 -0.001  0.034  0.002  \n",
       "topic_3     -0.001 -0.000 -0.008  0.012  \n",
       "topic_4     -0.000 -0.001  0.004 -0.003  \n",
       "\n",
       "[5 rows x 1381 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_star_topic_word = pd.DataFrame(area_star_lsa.components_.round(3),\n",
    "               index = ['topic_0','topic_1','topic_2','topic_3','topic_4'],\n",
    "             columns = area_star_cv.get_feature_names())\n",
    "area_star_topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f991a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 topic words\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25aefe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "new_york, st, san_francisco, mid, square, times, madison_square_garden, st_james_theatre, park, ing\n",
      "\n",
      "Topic  1\n",
      "san_francisco, oracle_park, historical, pier, ferry, muir, monument, woods, exploratorium, chase\n",
      "\n",
      "Topic  2\n",
      "chicago, pavilion, uic, wrigley, soldier_field, seattle, field, navy_pier, tower, the_loop\n",
      "\n",
      "Topic  3\n",
      "seattle, lumen_field, lake, union, climate_pledge_arena, el_corazon, pike_place_market, tmobile_park, wheel, westlake\n",
      "\n",
      "Topic  4\n",
      "los_angeles, staples, museum, santa_monica_pier, venice, la, pantages_theatre, belasco, wax, paramount_studios\n"
     ]
    }
   ],
   "source": [
    "display_topics(area_star_lsa, area_star_cv.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90193bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt = pd.DataFrame(area_star_doc_topic.round(5),\n",
    "             index = df.index,\n",
    "             columns = ['topic_0','topic_1','topic_2','topic_3','topic_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5786e5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13923,  0.06427,  0.27214, -0.0541 , -0.03183],\n",
       "       [ 0.12166,  0.06458,  0.34204, -0.06145, -0.01632],\n",
       "       [ 0.12348,  0.04936,  0.39403, -0.11169, -0.01508],\n",
       "       ...,\n",
       "       [ 0.22245,  0.52312, -0.12618, -0.03792, -0.03477],\n",
       "       [ 0.15057,  0.32544, -0.03065,  0.01772, -0.02837],\n",
       "       [ 0.25872,  0.4439 , -0.1038 ,  0.00312,  0.02489]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT = area_star_doc_topic.round(5)\n",
    "\n",
    "VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a2874a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc4b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 5 recommendations\n",
    "def get_recommendation(VT, hotelID, num_recom):\n",
    "    VT_df = pd.DataFrame(VT)\n",
    "    VT_df['city'] = df.city\n",
    "    \n",
    "    rec_list = []\n",
    "    for hotel in range(VT.shape[0]):\n",
    "        if VT_df.iloc[hotelID, VT_df.shape[1]-1] == VT_df.iloc[hotel, VT_df.shape[1]-1]:\n",
    "            if hotel != hotelID:\n",
    "                rec_list.append([hotel, np.dot(VT[hotelID], VT[hotel])])\n",
    "    top_rec = [i[0] for i in sorted(rec_list, key=lambda x: x[1], reverse=True)]\n",
    "    final_rec = top_rec[:num_recom]\n",
    "    return df.iloc[final_rec][['hotel', 'address', 'star']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f89829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>address</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Hyatt Place Seattle Downtown</td>\n",
       "      <td>110 6th Ave N, Seattle, WA, 98109</td>\n",
       "      <td>three stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Quality Inn and Suites Seattle Center Downtown</td>\n",
       "      <td>618 John Street, Seattle, WA, 98109</td>\n",
       "      <td>three stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Staypineapple, Hotel FIVE, Downtown Seattle</td>\n",
       "      <td>2200 Fifth Avenue, Seattle, WA, 98121</td>\n",
       "      <td>three stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Hilton Seattle</td>\n",
       "      <td>1301 6th Avenue, Seattle, WA, 98101</td>\n",
       "      <td>three stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Holiday Inn Seattle Downtown, an IHG Hotel</td>\n",
       "      <td>211 Dexter Ave N, Seattle, WA, 98109</td>\n",
       "      <td>three stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              hotel  \\\n",
       "223                    Hyatt Place Seattle Downtown   \n",
       "217  Quality Inn and Suites Seattle Center Downtown   \n",
       "197     Staypineapple, Hotel FIVE, Downtown Seattle   \n",
       "222                                  Hilton Seattle   \n",
       "202      Holiday Inn Seattle Downtown, an IHG Hotel   \n",
       "\n",
       "                                   address          star  \n",
       "223      110 6th Ave N, Seattle, WA, 98109   three stars  \n",
       "217    618 John Street, Seattle, WA, 98109   three stars  \n",
       "197  2200 Fifth Avenue, Seattle, WA, 98121   three stars  \n",
       "222    1301 6th Avenue, Seattle, WA, 98101   three stars  \n",
       "202   211 Dexter Ave N, Seattle, WA, 98109   three stars  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation(VT, 220, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca0a004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                       Oakwood at Via 6\n",
       "address    2121 6th Ave., Seattle, WA, 98121\n",
       "star                             three stars\n",
       "Name: 220, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[220, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd769af",
   "metadata": {},
   "source": [
    "The above are great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44a6475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>address</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Inn At Union Square</td>\n",
       "      <td>440 Post St, San Francisco, CA, 94102</td>\n",
       "      <td>three stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>The Ritz-Carlton, San Francisco</td>\n",
       "      <td>600 Stockton St, San Francisco, CA, 94108</td>\n",
       "      <td>five stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Courtyard by Marriott San Francisco Union Square</td>\n",
       "      <td>761 Post Street, San Francisco, CA, 94109</td>\n",
       "      <td>three stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>Union Square Plaza Hotel</td>\n",
       "      <td>432 Geary St, San Francisco, CA, 94102</td>\n",
       "      <td>two stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Le Meridien San Francisco</td>\n",
       "      <td>333 Battery St, San Francisco, CA, 94111</td>\n",
       "      <td>four stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hotel  \\\n",
       "909                               Inn At Union Square   \n",
       "991                   The Ritz-Carlton, San Francisco   \n",
       "897  Courtyard by Marriott San Francisco Union Square   \n",
       "832                          Union Square Plaza Hotel   \n",
       "957                         Le Meridien San Francisco   \n",
       "\n",
       "                                       address          star  \n",
       "909      440 Post St, San Francisco, CA, 94102   three stars  \n",
       "991  600 Stockton St, San Francisco, CA, 94108    five stars  \n",
       "897  761 Post Street, San Francisco, CA, 94109   three stars  \n",
       "832     432 Geary St, San Francisco, CA, 94102     two stars  \n",
       "957   333 Battery St, San Francisco, CA, 94111    four stars  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation(VT, 830, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56ccdd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                                 Powell Place\n",
       "address    730 Powell St, San Francisco, CA, 94108\n",
       "star                                     two stars\n",
       "Name: 830, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[830, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854e36d",
   "metadata": {},
   "source": [
    "These are bad reccommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db2889",
   "metadata": {},
   "source": [
    "Recommendation system with TruncatedSVD gave extreme results; one was excellent, and the other was way off."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
